{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c2d9c40",
   "metadata": {},
   "source": [
    "# GPU + Datasets: Starting with Pandas\n",
    "\n",
    "This notebook shows how to **measure** where the GPU helps (and where it doesn’t) when working with datasets.\n",
    "\n",
    "Important clarification up-front:\n",
    "- **Pandas itself is CPU-based**. It does not execute groupby/join/filter on the GPU.\n",
    "- To use a GPU for dataframe-style operations, you typically switch to **cuDF** (RAPIDS), which has a pandas-like API.\n",
    "- A very common workflow is: **pandas for I/O + ETL → GPU tensors for heavy compute/training**.\n",
    "\n",
    "This notebook demonstrates both patterns with safe fallbacks if GPU libs aren’t installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc65dd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform: Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.39\n",
      "Python: 3.12.12\n",
      "pandas: 2.3.3\n",
      "numpy: 2.2.6\n",
      "torch: 2.9.1\n",
      "torch CUDA available: True\n",
      "torch GPU: NVIDIA RTX A4000 Laptop GPU\n",
      "cupy: 13.6.0\n",
      "cupy device count: 1\n",
      "\n",
      "Notes: PyTorch sees a CUDA GPU; CuPy sees a CUDA GPU\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "from time import perf_counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print('Platform:', platform.platform())\n",
    "print('Python:', platform.python_version())\n",
    "print('pandas:', pd.__version__)\n",
    "print('numpy:', np.__version__)\n",
    "\n",
    "# GPU visibility checks (best-effort)\n",
    "gpu_notes = []\n",
    "try:\n",
    "    import torch\n",
    "    print('torch:', torch.__version__)\n",
    "    print('torch CUDA available:', torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        print('torch GPU:', torch.cuda.get_device_name(0))\n",
    "        gpu_notes.append('PyTorch sees a CUDA GPU')\n",
    "    else:\n",
    "        gpu_notes.append('PyTorch does not see a CUDA GPU')\n",
    "except Exception as e:\n",
    "    print('torch not available or failed to import:', repr(e))\n",
    "    gpu_notes.append('PyTorch not available')\n",
    "\n",
    "try:\n",
    "    import cupy as cp\n",
    "    print('cupy:', cp.__version__)\n",
    "    n = cp.cuda.runtime.getDeviceCount()\n",
    "    print('cupy device count:', n)\n",
    "    if n > 0:\n",
    "        gpu_notes.append('CuPy sees a CUDA GPU')\n",
    "except Exception as e:\n",
    "    print('cupy not available (this is OK):', repr(e))\n",
    "\n",
    "print('\\nNotes:', '; '.join(gpu_notes) if gpu_notes else '(none)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a4c50ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cudf OK\n",
      "cudf.pandas OK\n",
      "ipython: True\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "for mod in [\"cudf\", \"cudf.pandas\"]:\n",
    "    try:\n",
    "        importlib.import_module(mod)\n",
    "        print(mod, \"OK\")\n",
    "    except Exception as e:\n",
    "        print(mod, \"FAILED:\", repr(e))\n",
    "\n",
    "from IPython import get_ipython\n",
    "print(\"ipython:\", get_ipython() is not None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b38376",
   "metadata": {},
   "source": [
    "## Quick note: what is CuPy (and why it’s optional here)?\n",
    "\n",
    "**CuPy** is a NumPy-like array library that runs many operations on an NVIDIA GPU via CUDA.\n",
    "It’s useful when you want to do \"NumPy-style\" compute on the GPU (e.g., large elementwise ops, reductions, some linear algebra), without switching to a deep-learning framework.\n",
    "\n",
    "In this notebook:\n",
    "- We *do not require* CuPy. The import is a best-effort check so you can see whether it’s available in your environment.\n",
    "- If CuPy is missing, that’s totally fine: the rest of the notebook still works (pandas on CPU, and PyTorch on GPU if available).\n",
    "\n",
    "How it relates to PyTorch:\n",
    "- **PyTorch** is usually the right choice for GPU-accelerated training and tensor compute for ML.\n",
    "- **CuPy** can be handy for GPU-accelerating parts of a pipeline that feel like NumPy, or for quick GPU array experiments.\n",
    "\n",
    "About Windows availability (high-level):\n",
    "- CuPy can work on Windows, but you typically need a compatible NVIDIA driver + CUDA runtime/toolkit setup, and you must install a CuPy build that matches your CUDA version.\n",
    "- In practice, many people find CuPy easiest to use on Linux/WSL for reproducible CUDA environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08d593c",
   "metadata": {},
   "source": [
    "## Optional: cuDF “pandas accelerator” (drop-in, when available)\n",
    "\n",
    "If you have RAPIDS/cuDF installed (typically easiest on Linux/WSL), you can enable an optional **pandas accelerator**:\n",
    "- It hooks into parts of the pandas API and runs supported operations on the GPU.\n",
    "- It’s *not* guaranteed to accelerate every pandas operation; coverage depends on your versions and the operation types.\n",
    "- If it’s not installed, the cell just prints a message and everything continues on CPU as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dae2df0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU acceleration enabled via cudf.pandas\n",
      "cuDF: 25.12.00 | CuPy: 13.6.0\n",
      "GPU count: 1\n",
      "[0] NVIDIA RTX A4000 Laptop GPU - 7 GB\n"
     ]
    }
   ],
   "source": [
    "# Optional GPU acceleration: enable cuDF's pandas accelerator if available\n",
    "# Notes:\n",
    "# - RAPIDS/cuDF is typically easiest on Linux/WSL (not native Windows).\n",
    "# - CUDA Toolkit works on native Windows, but RAPIDS libraries generally target Linux environments.\n",
    "# - If this isn't installed, we continue with regular CPU pandas.\n",
    "\n",
    "GPU_ACCEL = False\n",
    "try:\n",
    "    from IPython import get_ipython\n",
    "    ip = get_ipython()  # available in notebooks\n",
    "    if ip is not None:\n",
    "        ip.run_line_magic('load_ext', 'cudf.pandas')\n",
    "        GPU_ACCEL = True\n",
    "except Exception:\n",
    "    GPU_ACCEL = False\n",
    "\n",
    "if GPU_ACCEL:\n",
    "    print('GPU acceleration enabled via cudf.pandas')\n",
    "    try:\n",
    "        import cudf\n",
    "        import cupy as cp\n",
    "        print('cuDF:', cudf.__version__, '| CuPy:', cp.__version__)\n",
    "        n = cp.cuda.runtime.getDeviceCount()\n",
    "        print('GPU count:', n)\n",
    "        for i in range(n):\n",
    "            p = cp.cuda.runtime.getDeviceProperties(i)\n",
    "            name = p['name'].decode() if isinstance(p.get('name'), (bytes, bytearray)) else str(p.get('name'))\n",
    "            mem_gb = int(p['totalGlobalMem']) // (1024**3)\n",
    "            print(f'[{i}] {name} - {mem_gb} GB')\n",
    "    except Exception as e:\n",
    "        print('Accelerator enabled, but failed to query GPU details:', repr(e))\n",
    "else:\n",
    "    print('GPU acceleration disabled (cudf.pandas not available).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2350714",
   "metadata": {},
   "source": [
    "## Step 1 — Create a dataset in pandas (CPU)\n",
    "\n",
    "We’ll create a synthetic dataset that looks like a common analytics table:\n",
    "- `user_id` (categorical-ish id)\n",
    "- `country` (category)\n",
    "- `amount` (numeric)\n",
    "- `timestamp` (integer)\n",
    "\n",
    "Then we’ll benchmark typical operations: filter + groupby aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "938a637a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created df: (1000000, 4)\n",
      "Create time: 0.216s\n",
      "Memory usage (MB): 16.21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>country</th>\n",
       "      <th>amount</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170124</td>\n",
       "      <td>US</td>\n",
       "      <td>39.621334</td>\n",
       "      <td>1710486851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127392</td>\n",
       "      <td>CA</td>\n",
       "      <td>3.628782</td>\n",
       "      <td>1708395330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102227</td>\n",
       "      <td>BR</td>\n",
       "      <td>141.211502</td>\n",
       "      <td>1707076564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53957</td>\n",
       "      <td>MX</td>\n",
       "      <td>18.642044</td>\n",
       "      <td>1701269503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61565</td>\n",
       "      <td>JP</td>\n",
       "      <td>66.881958</td>\n",
       "      <td>1701723546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id country      amount   timestamp\n",
       "0   170124      US   39.621334  1710486851\n",
       "1   127392      CA    3.628782  1708395330\n",
       "2   102227      BR  141.211502  1707076564\n",
       "3    53957      MX   18.642044  1701269503\n",
       "4    61565      JP   66.881958  1701723546"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune dataset size here.\n",
    "# 1_000_000 rows is a reasonable starting point for timing experiments.\n",
    "N = 1_000_000\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "countries = np.array(['US', 'CA', 'MX', 'BR', 'GB', 'DE', 'FR', 'IN', 'JP', 'AU'])\n",
    "\n",
    "t0 = perf_counter()\n",
    "df = pd.DataFrame({\n",
    "    'user_id': rng.integers(0, 200_000, size=N, dtype=np.int32),\n",
    "    'country': rng.choice(countries, size=N),\n",
    "    'amount': rng.gamma(shape=2.0, scale=20.0, size=N).astype('float32'),\n",
    "    'timestamp': rng.integers(1_700_000_000, 1_720_000_000, size=N, dtype=np.int64),\n",
    "})\n",
    "\n",
    "# Make `country` a categorical column (common in real datasets)\n",
    "df['country'] = df['country'].astype('category')\n",
    "\n",
    "t1 = perf_counter()\n",
    "print('Created df:', df.shape)\n",
    "print('Create time: %.3fs' % (t1 - t0))\n",
    "print('Memory usage (MB):', round(df.memory_usage(deep=True).sum() / (1024**2), 2))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ae579b",
   "metadata": {},
   "source": [
    "## Step 2 — CPU baseline: groupby + aggregation in pandas\n",
    "\n",
    "This is the kind of operation people often want to accelerate.\n",
    "\n",
    "We’ll do:\n",
    "- filter to a subset of users\n",
    "- group by `country`\n",
    "- compute `count`, `mean(amount)`, `sum(amount)`\n",
    "\n",
    "We time it to create a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbbcd9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU (pandas) time: 0.018s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IN</th>\n",
       "      <td>24956</td>\n",
       "      <td>40.325600</td>\n",
       "      <td>1.006366e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>25134</td>\n",
       "      <td>39.968784</td>\n",
       "      <td>1.004575e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE</th>\n",
       "      <td>25033</td>\n",
       "      <td>40.089798</td>\n",
       "      <td>1.003568e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MX</th>\n",
       "      <td>25151</td>\n",
       "      <td>39.849327</td>\n",
       "      <td>1.002250e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>25064</td>\n",
       "      <td>39.952671</td>\n",
       "      <td>1.001374e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JP</th>\n",
       "      <td>24896</td>\n",
       "      <td>40.141140</td>\n",
       "      <td>9.993538e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AU</th>\n",
       "      <td>25051</td>\n",
       "      <td>39.864948</td>\n",
       "      <td>9.986568e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>24849</td>\n",
       "      <td>39.827011</td>\n",
       "      <td>9.896614e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FR</th>\n",
       "      <td>24794</td>\n",
       "      <td>39.868832</td>\n",
       "      <td>9.885078e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BR</th>\n",
       "      <td>24650</td>\n",
       "      <td>40.077881</td>\n",
       "      <td>9.879198e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count       mean           sum\n",
       "country                                \n",
       "IN       24956  40.325600  1.006366e+06\n",
       "US       25134  39.968784  1.004575e+06\n",
       "DE       25033  40.089798  1.003568e+06\n",
       "MX       25151  39.849327  1.002250e+06\n",
       "GB       25064  39.952671  1.001374e+06\n",
       "JP       24896  40.141140  9.993538e+05\n",
       "AU       25051  39.864948  9.986568e+05\n",
       "CA       24849  39.827011  9.896614e+05\n",
       "FR       24794  39.868832  9.885078e+05\n",
       "BR       24650  40.077881  9.879198e+05"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = perf_counter()\n",
    "\n",
    "filtered = df[df['user_id'] < 50_000]\n",
    "result_cpu = (\n",
    "    filtered.groupby('country', observed=True)['amount']\n",
    "    .agg(['count', 'mean', 'sum'])\n",
    "    .sort_values('sum', ascending=False)\n",
    ")\n",
    "\n",
    "t1 = perf_counter()\n",
    "print('CPU (pandas) time: %.3fs' % (t1 - t0))\n",
    "result_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ed1640",
   "metadata": {},
   "source": [
    "## Step 2.5 — Optional: NumPy vs CuPy micro-benchmarks (GPU arrays)\n",
    "\n",
    "This section answers: **if we move numeric arrays to the GPU, is it faster?**\n",
    "\n",
    "> Important: this does *not* accelerate pandas `groupby` (pandas is CPU).\n",
    "CuPy helps when your workload looks like **NumPy math** (elementwise ops, reductions, matrix multiplications, etc.).\n",
    "\n",
    "We measure three things separately:\n",
    "- Host→Device transfer (CPU → GPU copy)\n",
    "- GPU compute time (with synchronization)\n",
    "- Device→Host transfer (GPU → CPU copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d45a18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CuPy: 13.6.0\n",
      "[0] NVIDIA RTX A4000 Laptop GPU - 7 GB\n",
      "\n",
      "Using df[\"amount\"] from Step 1: (1000000,)\n",
      "[Elemwise+sum] NumPy CPU: best=1.25 ms | median=1.60 ms | worst=2.92 ms | runs=5\n",
      "[Elemwise+sum] NumPy sum: 9.409e+06\n",
      "[Elemwise] CuPy H2D: 6.16 ms\n",
      "[Elemwise] CuPy GPU compute: best=1.81 ms | median=1.96 ms | worst=11.81 ms | runs=5\n",
      "[Elemwise+sum] CuPy reduction+scalar D2H: 27.09 ms\n",
      "[Elemwise+sum] CuPy sum: 9.409e+06\n",
      "[Elemwise] CuPy full-array D2H: 3.02 ms\n",
      "[Matmul 4096x4096] NumPy CPU: best=311.88 ms | median=314.66 ms | worst=316.54 ms | runs=3\n",
      "[Matmul 4096x4096] CuPy GPU compute: best=17.68 ms | median=22.55 ms | worst=24.92 ms | runs=5\n",
      "[Matmul 4096x4096] CuPy D2H (result copy): 31.83 ms\n"
     ]
    }
   ],
   "source": [
    "# If CuPy isn't installed, this cell will print a message and skip.\n",
    "# Install (optional) in this repo with:  uv sync --extra gpu\n",
    "\n",
    "from time import perf_counter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def _ms(dt: float) -> float:\n",
    "    return 1e3 * dt\n",
    "\n",
    "def _summarize_ms(name: str, values_ms: list[float]) -> None:\n",
    "    values_ms = [float(v) for v in values_ms]\n",
    "    values_ms_sorted = sorted(values_ms)\n",
    "    mid = values_ms_sorted[len(values_ms_sorted) // 2]\n",
    "    best = values_ms_sorted[0]\n",
    "    worst = values_ms_sorted[-1]\n",
    "    print(f'{name}: best={best:.2f} ms | median={mid:.2f} ms | worst={worst:.2f} ms | runs={len(values_ms_sorted)}')\n",
    "\n",
    "try:\n",
    "    import cupy as cp\n",
    "except Exception as e:\n",
    "    cp = None\n",
    "    print('CuPy not available (skipping):', repr(e))\n",
    "\n",
    "if cp is not None:\n",
    "    # Basic CUDA sanity check\n",
    "    try:\n",
    "        n = cp.cuda.runtime.getDeviceCount()\n",
    "    except Exception as e:\n",
    "        n = 0\n",
    "        print('CuPy installed, but CUDA is not usable (skipping):', repr(e))\n",
    "\n",
    "    if n <= 0:\n",
    "        print('No CUDA GPU visible to CuPy (skipping).')\n",
    "    else:\n",
    "        print('CuPy:', cp.__version__)\n",
    "        p0 = cp.cuda.runtime.getDeviceProperties(0)\n",
    "        name0 = p0['name'].decode() if isinstance(p0.get('name'), (bytes, bytearray)) else str(p0.get('name'))\n",
    "        mem0_gb = int(p0['totalGlobalMem']) // (1024**3)\n",
    "        print(f'[0] {name0} - {mem0_gb} GB')\n",
    "\n",
    "        # -----------------------------\n",
    "        # Benchmark 1: elementwise + reduction\n",
    "        # -----------------------------\n",
    "        # Prefer using the pandas dataframe if you've already created it (Step 1).\n",
    "        # Otherwise fall back to a synthetic array so this cell can run standalone.\n",
    "        if 'df' in globals() and hasattr(globals()['df'], '__getitem__') and 'amount' in globals()['df'].columns:\n",
    "            x_np = globals()['df']['amount'].to_numpy(dtype='float32')\n",
    "            print('\\nUsing df[\"amount\"] from Step 1:', x_np.shape)\n",
    "        else:\n",
    "            x_np = np.random.default_rng(0).gamma(shape=2.0, scale=20.0, size=1_000_000).astype('float32')\n",
    "            print('\\nUsing synthetic x_np:', x_np.shape)\n",
    "\n",
    "        # NumPy baseline (CPU) — run a few times and summarize\n",
    "        _ = np.log1p(x_np[:10])  # tiny warmup\n",
    "        cpu_times = []\n",
    "        for _ in range(5):\n",
    "            t0 = perf_counter()\n",
    "            y_np = np.sqrt(x_np) + np.log1p(x_np)\n",
    "            s_np = float(y_np.sum())\n",
    "            t1 = perf_counter()\n",
    "            cpu_times.append(_ms(t1 - t0))\n",
    "        _summarize_ms('[Elemwise+sum] NumPy CPU', cpu_times)\n",
    "        print('[Elemwise+sum] NumPy sum:', f'{s_np:.3e}')\n",
    "\n",
    "        # CuPy: measure transfer + GPU compute (separately), and optional D2H copy\n",
    "        # Warmup to reduce one-time init effects\n",
    "        _warm = cp.asarray(x_np[:1024])\n",
    "        _warm = cp.sqrt(_warm)\n",
    "        cp.cuda.Stream.null.synchronize()\n",
    "\n",
    "        # Host -> Device copy\n",
    "        t0 = perf_counter()\n",
    "        x_cp = cp.asarray(x_np)\n",
    "        cp.cuda.Stream.null.synchronize()\n",
    "        t1 = perf_counter()\n",
    "        print('[Elemwise] CuPy H2D:', f'{_ms(t1 - t0):.2f} ms')\n",
    "\n",
    "        # GPU compute timing using CUDA events (more stable than perf_counter for GPU ops)\n",
    "        # We exclude the initial run from stats to reduce startup effects.\n",
    "        gpu_times = []\n",
    "        for rep in range(6):\n",
    "            start = cp.cuda.Event()\n",
    "            end = cp.cuda.Event()\n",
    "            start.record()\n",
    "            y_cp = cp.sqrt(x_cp) + cp.log1p(x_cp)\n",
    "            end.record()\n",
    "            end.synchronize()\n",
    "            dt_ms = cp.cuda.get_elapsed_time(start, end)\n",
    "            if rep > 0:\n",
    "                gpu_times.append(float(dt_ms))\n",
    "        _summarize_ms('[Elemwise] CuPy GPU compute', gpu_times)\n",
    "\n",
    "        # Reduction + scalar copy back (small, but we show it explicitly)\n",
    "        t0 = perf_counter()\n",
    "        s_cp = float(cp.sum(y_cp).get())\n",
    "        t1 = perf_counter()\n",
    "        print('[Elemwise+sum] CuPy reduction+scalar D2H:', f'{_ms(t1 - t0):.2f} ms')\n",
    "        print('[Elemwise+sum] CuPy sum:', f'{s_cp:.3e}')\n",
    "\n",
    "        # Optional: cost to copy a large result array back to CPU\n",
    "        t0 = perf_counter()\n",
    "        _ = cp.asnumpy(y_cp)\n",
    "        t1 = perf_counter()\n",
    "        print('[Elemwise] CuPy full-array D2H:', f'{_ms(t1 - t0):.2f} ms')\n",
    "\n",
    "        # -----------------------------\n",
    "        # Benchmark 2: matrix multiply (compute-only, GPU resident)\n",
    "        # -----------------------------\n",
    "        # For small matrices the CPU can be surprisingly competitive;\n",
    "        # increase N to see clearer GPU wins (watch VRAM).\n",
    "        N = 4096 if mem0_gb >= 7 else 3072\n",
    "        rng = np.random.default_rng(0)\n",
    "\n",
    "        def _cpu_matmul_ms(A, B):\n",
    "            _ = A @ B  # warmup\n",
    "            times = []\n",
    "            for _ in range(3):\n",
    "                t0 = perf_counter()\n",
    "                _ = A @ B\n",
    "                t1 = perf_counter()\n",
    "                times.append(_ms(t1 - t0))\n",
    "            return times\n",
    "\n",
    "        def _gpu_matmul_ms(Ag, Bg):\n",
    "            _ = Ag @ Bg  # warmup\n",
    "            cp.cuda.Stream.null.synchronize()\n",
    "            times = []\n",
    "            Cg = None\n",
    "            for rep in range(6):\n",
    "                start = cp.cuda.Event()\n",
    "                end = cp.cuda.Event()\n",
    "                start.record()\n",
    "                Cg = Ag @ Bg\n",
    "                end.record()\n",
    "                end.synchronize()\n",
    "                dt_ms = cp.cuda.get_elapsed_time(start, end)\n",
    "                if rep > 0:\n",
    "                    times.append(float(dt_ms))\n",
    "            return times, Cg\n",
    "\n",
    "        try:\n",
    "            A = rng.standard_normal((N, N), dtype=np.float32)\n",
    "            B = rng.standard_normal((N, N), dtype=np.float32)\n",
    "        except MemoryError:\n",
    "            N = 2048\n",
    "            A = rng.standard_normal((N, N), dtype=np.float32)\n",
    "            B = rng.standard_normal((N, N), dtype=np.float32)\n",
    "            print('Fell back to N=2048 due to host memory limits.')\n",
    "\n",
    "        cpu_mm_times = _cpu_matmul_ms(A, B)\n",
    "        _summarize_ms(f'[Matmul {N}x{N}] NumPy CPU', cpu_mm_times)\n",
    "\n",
    "        Ag = cp.asarray(A)\n",
    "        Bg = cp.asarray(B)\n",
    "        gpu_mm_times, Cg = _gpu_matmul_ms(Ag, Bg)\n",
    "        _summarize_ms(f'[Matmul {N}x{N}] CuPy GPU compute', gpu_mm_times)\n",
    "\n",
    "        t0 = perf_counter()\n",
    "        _ = cp.asnumpy(Cg)\n",
    "        t1 = perf_counter()\n",
    "        print(f'[Matmul {N}x{N}] CuPy D2H (result copy): {_ms(t1 - t0):.2f} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e75145",
   "metadata": {},
   "source": [
    "## Step 2.6 — “Groupby-like” aggregation without cuDF (NumPy vs CuPy)\n",
    "\n",
    "If you specifically want to compare **pandas-style aggregation** with a **CuPy implementation**, here’s a good pattern:\n",
    "- Use pandas once to do the *dataframe-ish* parts (I/O, cleaning, categories).\n",
    "- Convert the relevant columns to plain arrays.\n",
    "- Implement the aggregation using `bincount` (fast on CPU with NumPy, and on GPU with CuPy).\n",
    "\n",
    "This is not “CuPy running pandas”, but it *does* run the same math as a common pandas `groupby(...).agg(...)` using GPU arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e217e93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Groupby] pandas (CPU): best=21.48 ms | median=22.12 ms | worst=25.41 ms | runs=3\n",
      "[Groupby] NumPy bincount (CPU): best=3.91 ms | median=5.80 ms | worst=10.68 ms | runs=5\n",
      "NumPy vs pandas max abs diff | sum: 0.119151 | mean: 2.92245e-06\n",
      "[Groupby] CuPy H2D: 5.89 ms\n",
      "[Groupby] CuPy bincount GPU compute: best=4.34 ms | median=4.56 ms | worst=11.08 ms | runs=5\n",
      "[Groupby] CuPy D2H: 0.30 ms\n",
      "CuPy vs pandas max abs diff | sum: 0.119151 | mean: 2.92245e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pandas_count</th>\n",
       "      <th>pandas_sum</th>\n",
       "      <th>pandas_mean</th>\n",
       "      <th>cupy_count</th>\n",
       "      <th>cupy_sum</th>\n",
       "      <th>cupy_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AU</th>\n",
       "      <td>100339</td>\n",
       "      <td>4005580.50</td>\n",
       "      <td>39.920475</td>\n",
       "      <td>100339</td>\n",
       "      <td>4.005580e+06</td>\n",
       "      <td>39.920474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BR</th>\n",
       "      <td>99854</td>\n",
       "      <td>3988503.00</td>\n",
       "      <td>39.943348</td>\n",
       "      <td>99854</td>\n",
       "      <td>3.988503e+06</td>\n",
       "      <td>39.943348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>100010</td>\n",
       "      <td>4001330.50</td>\n",
       "      <td>40.009304</td>\n",
       "      <td>100010</td>\n",
       "      <td>4.001330e+06</td>\n",
       "      <td>40.009303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE</th>\n",
       "      <td>100048</td>\n",
       "      <td>3998313.25</td>\n",
       "      <td>39.963951</td>\n",
       "      <td>100048</td>\n",
       "      <td>3.998313e+06</td>\n",
       "      <td>39.963951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FR</th>\n",
       "      <td>99808</td>\n",
       "      <td>3986569.75</td>\n",
       "      <td>39.942387</td>\n",
       "      <td>99808</td>\n",
       "      <td>3.986570e+06</td>\n",
       "      <td>39.942386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pandas_count  pandas_sum  pandas_mean  cupy_count      cupy_sum  \\\n",
       "country                                                                    \n",
       "AU             100339  4005580.50    39.920475      100339  4.005580e+06   \n",
       "BR              99854  3988503.00    39.943348       99854  3.988503e+06   \n",
       "CA             100010  4001330.50    40.009304      100010  4.001330e+06   \n",
       "DE             100048  3998313.25    39.963951      100048  3.998313e+06   \n",
       "FR              99808  3986569.75    39.942387       99808  3.986570e+06   \n",
       "\n",
       "         cupy_mean  \n",
       "country             \n",
       "AU       39.920474  \n",
       "BR       39.943348  \n",
       "CA       40.009303  \n",
       "DE       39.963951  \n",
       "FR       39.942386  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Benchmark: pandas groupby vs NumPy bincount vs CuPy bincount\n",
    "#\n",
    "# This is a nice “apples-to-apples” idea because all three compute the same outputs:\n",
    "#   count(country), sum(amount), mean(amount)\n",
    "# but via different execution backends (pandas/CPU, numpy/CPU, cupy/GPU).\n",
    "\n",
    "from time import perf_counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def _ms(dt: float) -> float:\n",
    "    return 1e3 * dt\n",
    "\n",
    "def _summarize_ms(name: str, values_ms: list[float]) -> None:\n",
    "    values_ms = [float(v) for v in values_ms]\n",
    "    values_ms_sorted = sorted(values_ms)\n",
    "    mid = values_ms_sorted[len(values_ms_sorted) // 2]\n",
    "    best = values_ms_sorted[0]\n",
    "    worst = values_ms_sorted[-1]\n",
    "    print(f'{name}: best={best:.2f} ms | median={mid:.2f} ms | worst={worst:.2f} ms | runs={len(values_ms_sorted)}')\n",
    "\n",
    "if 'df' not in globals():\n",
    "    raise RuntimeError('Run Step 1 first so df exists (the dataset creation cell).')\n",
    "\n",
    "if 'country' not in df.columns or 'amount' not in df.columns:\n",
    "    raise RuntimeError('df must contain country and amount columns.')\n",
    "\n",
    "# Ensure categorical encoding exists (so we can map country -> small int codes)\n",
    "if not isinstance(df['country'].dtype, pd.CategoricalDtype):\n",
    "    df['country'] = df['country'].astype('category')\n",
    "\n",
    "codes_np = df['country'].cat.codes.to_numpy(dtype=np.int32)\n",
    "amount_np = df['amount'].to_numpy(dtype=np.float32)\n",
    "k = int(df['country'].cat.categories.size)\n",
    "labels = df['country'].cat.categories.to_list()\n",
    "\n",
    "# -----------------------------\n",
    "# 1) pandas groupby baseline (CPU)\n",
    "# -----------------------------\n",
    "pandas_times = []\n",
    "for _ in range(3):\n",
    "    t0 = perf_counter()\n",
    "    gb = df.groupby('country', observed=True)['amount'].agg(['count', 'sum', 'mean']).sort_index()\n",
    "    t1 = perf_counter()\n",
    "    pandas_times.append(_ms(t1 - t0))\n",
    "_summarize_ms('[Groupby] pandas (CPU)', pandas_times)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) NumPy implementation (CPU)\n",
    "# -----------------------------\n",
    "numpy_times = []\n",
    "for _ in range(5):\n",
    "    t0 = perf_counter()\n",
    "    counts = np.bincount(codes_np, minlength=k).astype(np.int64)\n",
    "    sums = np.bincount(codes_np, weights=amount_np, minlength=k).astype(np.float64)\n",
    "    means = sums / np.maximum(counts, 1)\n",
    "    t1 = perf_counter()\n",
    "    numpy_times.append(_ms(t1 - t0))\n",
    "_summarize_ms('[Groupby] NumPy bincount (CPU)', numpy_times)\n",
    "\n",
    "# Build a comparable table (CPU)\n",
    "numpy_tbl = pd.DataFrame({'count': counts, 'sum': sums, 'mean': means}, index=labels)\n",
    "numpy_tbl.index.name = 'country'\n",
    "numpy_tbl = numpy_tbl.sort_index()\n",
    "\n",
    "# Quick correctness check (vs pandas)\n",
    "# Note: float sums may differ at tiny eps due to different reduction orders.\n",
    "max_abs_sum_diff = float(np.max(np.abs(numpy_tbl['sum'].to_numpy() - gb['sum'].to_numpy())))\n",
    "max_abs_mean_diff = float(np.max(np.abs(numpy_tbl['mean'].to_numpy() - gb['mean'].to_numpy())))\n",
    "print('NumPy vs pandas max abs diff | sum:', f'{max_abs_sum_diff:.6g}', '| mean:', f'{max_abs_mean_diff:.6g}')\n",
    "\n",
    "# -----------------------------\n",
    "# 3) CuPy implementation (GPU)\n",
    "# -----------------------------\n",
    "try:\n",
    "    import cupy as cp\n",
    "except Exception as e:\n",
    "    cp = None\n",
    "    print('CuPy not available (skipping GPU bincount):', repr(e))\n",
    "\n",
    "if cp is not None:\n",
    "    # Host -> Device transfers\n",
    "    t0 = perf_counter()\n",
    "    codes_cp = cp.asarray(codes_np)\n",
    "    amount_cp = cp.asarray(amount_np)\n",
    "    cp.cuda.Stream.null.synchronize()\n",
    "    t1 = perf_counter()\n",
    "    print('[Groupby] CuPy H2D:', f'{_ms(t1 - t0):.2f} ms')\n",
    "\n",
    "    # GPU compute timing using CUDA events\n",
    "    gpu_times = []\n",
    "    counts_cp = None\n",
    "    sums_cp = None\n",
    "    for rep in range(6):\n",
    "        start = cp.cuda.Event()\n",
    "        end = cp.cuda.Event()\n",
    "        start.record()\n",
    "        counts_cp = cp.bincount(codes_cp, minlength=k)\n",
    "        sums_cp = cp.bincount(codes_cp, weights=amount_cp, minlength=k)\n",
    "        end.record()\n",
    "        end.synchronize()\n",
    "        dt_ms = float(cp.cuda.get_elapsed_time(start, end))\n",
    "        if rep > 0:\n",
    "            gpu_times.append(dt_ms)\n",
    "    _summarize_ms('[Groupby] CuPy bincount GPU compute', gpu_times)\n",
    "\n",
    "    # Device -> Host transfer\n",
    "    t0 = perf_counter()\n",
    "    counts2 = cp.asnumpy(counts_cp).astype(np.int64)\n",
    "    sums2 = cp.asnumpy(sums_cp).astype(np.float64)\n",
    "    t1 = perf_counter()\n",
    "    print('[Groupby] CuPy D2H:', f'{_ms(t1 - t0):.2f} ms')\n",
    "\n",
    "    means2 = sums2 / np.maximum(counts2, 1)\n",
    "    cupy_tbl = pd.DataFrame({'count': counts2, 'sum': sums2, 'mean': means2}, index=labels)\n",
    "    cupy_tbl.index.name = 'country'\n",
    "    cupy_tbl = cupy_tbl.sort_index()\n",
    "\n",
    "    max_abs_sum_diff = float(np.max(np.abs(cupy_tbl['sum'].to_numpy() - gb['sum'].to_numpy())))\n",
    "    max_abs_mean_diff = float(np.max(np.abs(cupy_tbl['mean'].to_numpy() - gb['mean'].to_numpy())))\n",
    "    print('CuPy vs pandas max abs diff | sum:', f'{max_abs_sum_diff:.6g}', '| mean:', f'{max_abs_mean_diff:.6g}')\n",
    "\n",
    "    # Show just the top few rows to keep notebook output small\n",
    "    display(pd.concat([gb.add_prefix('pandas_'), cupy_tbl.add_prefix('cupy_')], axis=1).head())\n",
    "else:\n",
    "    display(pd.concat([gb.add_prefix('pandas_'), numpy_tbl.add_prefix('numpy_')], axis=1).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cfa113",
   "metadata": {},
   "source": [
    "## Step 3 — Optional: GPU dataframe acceleration with cuDF\n",
    "\n",
    "If you have a CUDA GPU and install RAPIDS/cuDF, you can run **pandas-like dataframe operations on the GPU**.\n",
    "\n",
    "Notes:\n",
    "- cuDF is not a pure-Python wheel for every OS/version combo; it’s typically easiest on Linux/WSL.\n",
    "- If cuDF isn’t installed, this section will skip.\n",
    "\n",
    "What we do:\n",
    "- Convert pandas → cuDF\n",
    "- Run the same filter + groupby aggregation\n",
    "- Compare timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a00f112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cudf: 25.12.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cudf = False\n",
    "try:\n",
    "    import cudf\n",
    "    use_cudf = True\n",
    "    print('cudf:', cudf.__version__)\n",
    "except Exception as e:\n",
    "    print('cuDF not available (skipping GPU dataframe benchmark).')\n",
    "    print('Reason:', repr(e))\n",
    "    print('If you want this section, you typically install RAPIDS/cuDF on Linux/WSL.')\n",
    "\n",
    "use_cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9daba8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted to cuDF: (1000000, 4)\n",
      "Convert time: 0.023s\n",
      "GPU (cuDF) time (includes to_pandas materialization): 0.171s\n"
     ]
    }
   ],
   "source": [
    "if use_cudf:\n",
    "    # Convert pandas -> cuDF (this costs time too, so we measure it separately)\n",
    "    t0 = perf_counter()\n",
    "    gdf = cudf.from_pandas(df)\n",
    "    t1 = perf_counter()\n",
    "    print('Converted to cuDF:', tuple(gdf.shape))\n",
    "    print('Convert time: %.3fs' % (t1 - t0))\n",
    "\n",
    "    # Run the same style of operation on GPU\n",
    "    t0 = perf_counter()\n",
    "    gfiltered = gdf[gdf['user_id'] < 50_000]\n",
    "    result_gpu = (\n",
    "        gfiltered.groupby('country')['amount']\n",
    "        .agg(['count', 'mean', 'sum'])\n",
    "        .sort_values('sum', ascending=False)\n",
    "    )\n",
    "    # Force computation before stopping the timer (GPU ops can be lazy)\n",
    "    _ = result_gpu.to_pandas()\n",
    "    t1 = perf_counter()\n",
    "    print('GPU (cuDF) time (includes to_pandas materialization): %.3fs' % (t1 - t0))\n",
    "\n",
    "    result_gpu.head()\n",
    "else:\n",
    "    print('Skipping: cuDF not installed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a216fc04",
   "metadata": {},
   "source": [
    "## Step 4 — Practical pattern: pandas ETL → GPU tensors for compute/training\n",
    "\n",
    "Even if you don’t use cuDF, you can still leverage the GPU by moving numeric arrays to GPU tensors.\n",
    "\n",
    "This is a very common real pattern:\n",
    "- Use **pandas** for cleaning, joining, feature engineering, encoding categories, etc.\n",
    "- Convert to **NumPy** arrays and then to **PyTorch** tensors\n",
    "- Run heavy compute/training on the GPU\n",
    "\n",
    "Below we create a tiny supervised learning task from the dataframe and train a small model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1da6d08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training device: cuda\n",
      "Train time (10 epochs): 0.299s\n",
      "Test accuracy: 0.9502\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import torch\n",
    "    from torch import nn\n",
    "except Exception as e:\n",
    "    raise RuntimeError('PyTorch is required for this section. Run `uv sync`.') from e\n",
    "\n",
    "# Create a simple target label from the data (synthetic but learnable):\n",
    "# label = 1 if amount is high AND user_id is in a certain range.\n",
    "# This is not a \"real\" ML problem, but it demonstrates the pipeline.\n",
    "features = df[['user_id', 'amount']].copy()\n",
    "features['user_id'] = (features['user_id'] / 200_000.0).astype('float32')\n",
    "X = features.to_numpy(dtype='float32')\n",
    "y = ((df['amount'].to_numpy(dtype='float32') > 60.0) & (df['user_id'].to_numpy() < 50_000)).astype('int64')\n",
    "\n",
    "# Train/test split\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Training device:', device)\n",
    "\n",
    "X_train_t = torch.from_numpy(X_train).to(device)\n",
    "y_train_t = torch.from_numpy(y_train).to(device)\n",
    "X_test_t = torch.from_numpy(X_test).to(device)\n",
    "y_test_t = torch.from_numpy(y_test).to(device)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 2)\n",
    ").to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "# Simple training loop (full-batch for clarity)\n",
    "t0 = perf_counter()\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    logits = model(X_train_t)\n",
    "    loss = loss_fn(logits, y_train_t)\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "t1 = perf_counter()\n",
    "print('Train time (10 epochs): %.3fs' % (t1 - t0))\n",
    "\n",
    "# Evaluate\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(X_test_t).argmax(dim=1)\n",
    "    acc = (pred == y_test_t).float().mean().item()\n",
    "print('Test accuracy:', round(acc, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fad90d",
   "metadata": {},
   "source": [
    "## Optional: download a real dataset (small)\n",
    "\n",
    "If you want to practice with a real CSV without huge downloads, this cell tries to pull a small dataset from GitHub.\n",
    "If you don’t have internet access, it will fail gracefully.\n",
    "\n",
    "(We keep this optional to avoid slowing down the main GPU experiments.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2b3e9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded penguins: (344, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 15067][18:17:03:297610][warning] Auto detection of compression type is supported only for file type buffers. For other buffer types, AUTO compression type assumes uncompressed input.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181</td>\n",
       "      <td>3750</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186</td>\n",
       "      <td>3800</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195</td>\n",
       "      <td>3250</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193</td>\n",
       "      <td>3450</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island bill_length_mm bill_depth_mm flipper_length_mm  \\\n",
       "0  Adelie  Torgersen           39.1          18.7               181   \n",
       "1  Adelie  Torgersen           39.5          17.4               186   \n",
       "2  Adelie  Torgersen           40.3          18.0               195   \n",
       "3  Adelie  Torgersen            nan           nan              <NA>   \n",
       "4  Adelie  Torgersen           36.7          19.3               193   \n",
       "\n",
       "  body_mass_g     sex  \n",
       "0        3750    MALE  \n",
       "1        3800  FEMALE  \n",
       "2        3250  FEMALE  \n",
       "3        <NA>    None  \n",
       "4        3450  FEMALE  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/penguins.csv'\n",
    "try:\n",
    "    penguins = pd.read_csv(url)\n",
    "    print('Downloaded penguins:', penguins.shape)\n",
    "    display(penguins.head())\n",
    "except Exception as e:\n",
    "    print('Download failed (this is OK):', repr(e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-25.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
