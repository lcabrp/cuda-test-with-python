{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59a5b3c7",
   "metadata": {},
   "source": [
    "### Testing with some operations    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2107624d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PyTorch ---\n",
      "torch version: 2.9.1+cu128\n",
      "CUDA available: True\n",
      "GPU name: NVIDIA RTX A4000 Laptop GPU\n",
      "\n",
      "--- TensorFlow ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-15 18:59:57.343367: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-15 18:59:57.387995: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-15 18:59:58.833584: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.20.0\n",
      "Built with CUDA: True\n",
      "Visible GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Quick GPU + package sanity check\n",
    "# This cell is written to be safe on machines *without* a GPU.\n",
    "\n",
    "print(\"--- PyTorch ---\")\n",
    "try:\n",
    "    import torch\n",
    "\n",
    "    print(\"torch version:\", torch.__version__)\n",
    "    cuda_ok = torch.cuda.is_available()\n",
    "    print(\"CUDA available:\", cuda_ok)\n",
    "\n",
    "    if cuda_ok:\n",
    "        device_index = 0\n",
    "        print(\"GPU name:\", torch.cuda.get_device_name(device_index))\n",
    "    else:\n",
    "        print(\"PyTorch will run on CPU (no CUDA device detected).\")\n",
    "except Exception as e:\n",
    "    print(\"PyTorch import/usage failed:\", repr(e))\n",
    "    print(\"If you expected PyTorch, install deps via: uv sync\")\n",
    "\n",
    "print(\"\\n--- TensorFlow ---\")\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "\n",
    "    print(\"tensorflow version:\", tf.__version__)\n",
    "    print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    print(\"Visible GPUs:\", gpus)\n",
    "\n",
    "    if not gpus:\n",
    "        print(\"TensorFlow will run on CPU (no GPU visible to TF).\")\n",
    "except Exception as e:\n",
    "    print(\"TensorFlow import/usage failed:\", repr(e))\n",
    "    print(\"If you expected TensorFlow, install deps via: uv sync\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78441f08",
   "metadata": {},
   "source": [
    "### Example: Accelerated Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b55bbffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Result shape: (5000, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication demo (GPU if available, otherwise CPU)\n",
    "#\n",
    "# This cell intentionally avoids hard-coding device='cuda' so it can run on:\n",
    "# - GPU machines (CUDA available)\n",
    "# - CPU-only machines (no CUDA / no NVIDIA GPU)\n",
    "\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using device:', device)\n",
    "\n",
    "# Create tensors on the selected device\n",
    "a = torch.randn(5000, 5000, device=device)\n",
    "b = torch.randn(5000, 5000, device=device)\n",
    "\n",
    "# Perform matrix multiplication\n",
    "c = torch.matmul(a, b)\n",
    "print('Result shape:', tuple(c.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f17893c",
   "metadata": {},
   "source": [
    "### Training Examples (TensorFlow)\n",
    "\n",
    "> There are **two** training examples below on purpose.\n",
    "\n",
    "- **Example 1: Synthetic (learnable) classification** — no downloads, runs fast, and is fully controlled so you can focus on the *ML workflow* (data → model → loss/optimizer → training → evaluation).\n",
    "- **Example 2: MNIST + mixed precision** — uses a real dataset and adds a practical GPU optimization technique (mixed precision) you’ll see in real projects.\n",
    "\n",
    "If you’re new to ML, run them in this order:\n",
    "1. Run Cell 2 (GPU + package sanity check)\n",
    "2. Run Cell 6 (Example 1: synthetic classification)\n",
    "3. Run Cell 9 (Example 2: MNIST + mixed precision)\n",
    "\n",
    "As you run them, watch these two ideas:\n",
    "- **Training accuracy vs validation accuracy**: training shows how well the model fits seen data; validation shows how it generalizes.\n",
    "- **Loss vs accuracy**: loss is what the optimizer actually minimizes; accuracy is a human-friendly metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2527cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Example 1 — Synthetic (learnable) classification on CPU or GPU (TensorFlow)\n",
    "\n",
    "Why this example exists:\n",
    "- It teaches the *mechanics* of training without external dependencies (no dataset downloads).\n",
    "- The labels are generated from a hidden linear rule, so the task is genuinely learnable (accuracy should rise).\n",
    "- It is small enough to iterate quickly while you experiment with batch size, epochs, and model depth.\n",
    "\n",
    "What to look for when you run it:\n",
    "- Accuracy should improve above random chance (~10% for 10 classes).\n",
    "- If a GPU is available, TensorFlow should use it automatically.\n",
    "\"\"\"\n",
    "\n",
    "# Beginner-friendly GPU training example (TensorFlow)\n",
    "\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "# Step 0: Make sure CUDA Toolkit binaries are discoverable by this kernel process\n",
    "#\n",
    "# On Linux/WSL, CUDA Toolkit is often installed under /usr/local/cuda.\n",
    "# Some TF/XLA GPU paths may call `ptxas` (part of the CUDA Toolkit).\n",
    "# VS Code/Jupyter kernels sometimes have a PATH that doesn’t include /usr/local/cuda/bin,\n",
    "# so we prepend it if it exists.\n",
    "cuda_bin = \"/usr/local/cuda/bin\"\n",
    "if os.path.isdir(cuda_bin):\n",
    "    path_parts = os.environ.get(\"PATH\", \"\").split(os.pathsep)\n",
    "    if cuda_bin not in path_parts:\n",
    "        os.environ[\"PATH\"] = cuda_bin + os.pathsep + os.environ.get(\"PATH\", \"\")\n",
    "\n",
    "ptxas_path = shutil.which(\"ptxas\")\n",
    "nvcc_path = shutil.which(\"nvcc\")\n",
    "print(\"ptxas:\", ptxas_path or \"NOT FOUND\")\n",
    "print(\"nvcc:\", nvcc_path or \"NOT FOUND\")\n",
    "\n",
    "# Import TensorFlow (after environment setup)\n",
    "import tensorflow as tf\n",
    "\n",
    "# Step 1: Configure GPU memory growth\n",
    "#\n",
    "# Without this, TensorFlow may try to reserve most/all VRAM up-front.\n",
    "# Memory growth lets TF allocate GPU memory as needed during training.\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"GPU memory growth enabled\")\n",
    "        print(\"GPU Available:\", gpus)\n",
    "        print(\"TensorFlow will automatically use GPU for ops\\n\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU configuration error: {e}\")\n",
    "else:\n",
    "    print(\"No GPU detected. Training will run on CPU.\\n\")\n",
    "\n",
    "# Step 2: Create a synthetic dataset that is *actually learnable*\n",
    "#\n",
    "# We generate labels from a hidden linear model:\n",
    "#   logits = X @ W + noise\n",
    "#   y = argmax(logits)\n",
    "#\n",
    "# If labels were random, the best you could do is ~10% accuracy forever.\n",
    "print(\"Generating learnable synthetic classification data...\")\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "num_train = 10_000\n",
    "num_test = 2_000\n",
    "num_features = 100\n",
    "num_classes = 10\n",
    "\n",
    "# Feature matrix (inputs)\n",
    "X_train = rng.normal(size=(num_train, num_features)).astype('float32')\n",
    "X_test = rng.normal(size=(num_test, num_features)).astype('float32')\n",
    "\n",
    "# Hidden weights used to generate labels (the pattern the model can learn)\n",
    "W = rng.normal(size=(num_features, num_classes)).astype('float32')\n",
    "noise_scale = 0.25\n",
    "\n",
    "train_logits = X_train @ W + rng.normal(scale=noise_scale, size=(num_train, num_classes)).astype('float32')\n",
    "test_logits = X_test @ W + rng.normal(scale=noise_scale, size=(num_test, num_classes)).astype('float32')\n",
    "\n",
    "# Integer labels (0..num_classes-1)\n",
    "y_train_int = np.argmax(train_logits, axis=1)\n",
    "y_test_int = np.argmax(test_logits, axis=1)\n",
    "\n",
    "# One-hot labels for categorical_crossentropy\n",
    "y_train = tf.keras.utils.to_categorical(y_train_int, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test_int, num_classes)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\\n\")\n",
    "\n",
    "# Step 3: Build a simple neural network\n",
    "#\n",
    "# Architecture: 100 → 64 (ReLU) → 10 (Softmax)\n",
    "#\n",
    "# - ReLU layer learns a non-linear representation of inputs.\n",
    "# - Softmax outputs class probabilities that sum to 1.\n",
    "print(\"Building model...\")\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(num_features,), name='hidden_layer'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax', name='output_layer'),\n",
    "])\n",
    "\n",
    "# Step 4: Compile (choose optimizer + loss + metrics)\n",
    "#\n",
    "# - Optimizer (Adam): how we update weights from gradients\n",
    "# - Loss (categorical_crossentropy): how wrong predictions are (what we minimize)\n",
    "# - Metric (accuracy): human-friendly score\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "print()\n",
    "\n",
    "# Step 5: Train\n",
    "print(\"Training model (GPU if available, otherwise CPU)...\")\n",
    "start_time = time.time()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=5,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"\\nTraining completed in {training_time:.2f} seconds\")\n",
    "\n",
    "# Step 6: Evaluate on held-out test data\n",
    "print(\"\\nEvaluating on test data...\")\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Step 7: Predict a few samples (show predicted class + confidence)\n",
    "print(\"\\nMaking predictions on 5 test samples...\")\n",
    "preds = model.predict(X_test[:5], verbose=0)\n",
    "for i, pred in enumerate(preds):\n",
    "    predicted_class = int(np.argmax(pred))\n",
    "    confidence = float(pred[predicted_class])\n",
    "    actual_class = int(np.argmax(y_test[i]))\n",
    "    print(f\"Sample {i+1}: Predicted={predicted_class} (confidence={confidence:.3f}), Actual={actual_class}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4df75f",
   "metadata": {},
   "source": [
    "### Training Example 2 (TensorFlow): MNIST + Mixed Precision\n",
    "\n",
    "This second example complements Example 1 by using a **real dataset** (MNIST handwritten digits).\n",
    "\n",
    "Why include this one:\n",
    "- You’ll see the typical preprocessing steps (normalize inputs, one-hot labels).\n",
    "- You’ll see a real benchmark-style dataset (so results are easier to interpret).\n",
    "- It demonstrates **mixed precision** (`mixed_float16`), a common GPU performance technique on modern NVIDIA GPUs (Tensor Cores).\n",
    "\n",
    "Note: MNIST may download the first time you run it (internet required)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afb7e4d",
   "metadata": {},
   "source": [
    "#### Key concepts in this example\n",
    "\n",
    "- **Mixed precision**: computations use float16 where safe (faster on many GPUs), while keeping some values in float32 for stability.\n",
    "- **Why the output layer uses `dtype='float32'`**: softmax + loss can be numerically sensitive; forcing float32 helps avoid instability when using float16.\n",
    "- **Normalization**: scaling pixel values to `[0, 1]` makes optimization easier.\n",
    "- **Train/validation split**: you’ll see whether improvements generalize, not just memorize.\n",
    "\n",
    "If you’re just starting out, try changing one thing at a time:\n",
    "- Increase/decrease `batch_size`\n",
    "- Increase `epochs`\n",
    "- Add/remove a Dense layer\n",
    "- Compare CPU vs GPU runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d1e473",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Example 2 — MNIST digits + mixed precision (TensorFlow)\n",
    "\n",
    "Why this example exists:\n",
    "- MNIST is a small *real* dataset, so training curves/accuracy are meaningful and comparable.\n",
    "- It shows standard image preprocessing (normalization) and label encoding.\n",
    "- It introduces mixed precision (`mixed_float16`), which can speed up training on many NVIDIA GPUs.\n",
    "\n",
    "Notes:\n",
    "- If you already ran Example 1, TensorFlow may already be imported; re-importing is fine.\n",
    "- MNIST may download the first time you run this cell (internet required).\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Step 1: Configure GPU memory growth (avoid grabbing all VRAM up-front)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"GPUs available:\", gpus)\n",
    "        details = tf.config.experimental.get_device_details(gpus[0])\n",
    "        print(\"Using GPU:\", details.get('device_name', 'Unknown GPU'))\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU detected. Training will run on CPU.\")\n",
    "\n",
    "# Step 2: Enable mixed precision (optional but useful on modern NVIDIA GPUs)\n",
    "#\n",
    "# mixed_float16 uses float16 for many computations for speed, but keeps variables/critical ops safe.\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "set_global_policy('mixed_float16')\n",
    "print(\"Mixed precision enabled: mixed_float16\")\n",
    "\n",
    "# Step 3: Load MNIST dataset\n",
    "print(\"\\nLoading MNIST dataset...\")\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Step 4: Normalize pixel values\n",
    "#\n",
    "# MNIST images are uint8 in [0, 255]. We convert to float32 and scale to [0, 1].\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Step 5: One-hot encode labels for categorical_crossentropy\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "print(f\"Training samples: {len(x_train)}, Test samples: {len(x_test)}\")\n",
    "\n",
    "# Step 6: Define a simple neural network model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    # Output layer forced to float32 for numerical stability with mixed precision\n",
    "    Dense(10, activation='softmax', dtype='float32')\n",
    "])\n",
    "\n",
    "# Step 7: Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Step 8: Train\n",
    "# Tip: batch size affects speed + memory. If you see OOM errors, reduce it further.\n",
    "print(\"\\nStarting training...\")\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_split=0.1,\n",
    "    epochs=5,\n",
    "    batch_size=64,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Step 9: Evaluate the model on test data\n",
    "print(\"\\nEvaluating model...\")\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-test-with-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
